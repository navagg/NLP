{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-fdfa47bc-6e46-48dc-b08f-b8b04ba7c1cc",
    "deepnote_cell_type": "text-cell-h1",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Learning NLP using FastAI Huggig Face Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-d662dfa6-f541-4309-9fec-5692fe9a1325",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### This Notebook can be used for learning NLP using Huuging Face Module. This notebook is created in DeepNote and We need to install the Fastai and Pytorch for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-d7add0ca-7f83-4125-8106-f890a9c8514a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4229,
    "execution_start": 1630222755438,
    "source_hash": "be529386",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai==2.5.2\n",
      "  Downloading fastai-2.5.2-py3-none-any.whl (186 kB)\n",
      "\u001b[K     |████████████████████████████████| 186 kB 24.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pip in /root/venv/lib/python3.7/site-packages (from fastai==2.5.2) (21.2.2)\n",
      "Collecting fastdownload<2,>=0.0.5\n",
      "  Downloading fastdownload-0.0.5-py3-none-any.whl (13 kB)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scipy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (1.7.1)\n",
      "Requirement already satisfied: requests in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (2.26.0)\n",
      "Collecting fastcore<1.4,>=1.3.8\n",
      "  Downloading fastcore-1.3.26-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 9.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (5.4.1)\n",
      "Requirement already satisfied: spacy<4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (3.1.1)\n",
      "Requirement already satisfied: torch<1.10,>=1.7.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (1.9.0)\n",
      "Requirement already satisfied: scikit-learn in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (0.24.2)\n",
      "Requirement already satisfied: matplotlib in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (3.4.2)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (0.10.0)\n",
      "Requirement already satisfied: pandas in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (1.2.5)\n",
      "Requirement already satisfied: pillow>6.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastai==2.5.2) (8.3.1)\n",
      "Requirement already satisfied: packaging in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from fastai==2.5.2) (21.0)\n",
      "Requirement already satisfied: numpy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fastprogress>=0.2.4->fastai==2.5.2) (1.19.5)\n",
      "Requirement already satisfied: jinja2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (3.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (4.62.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (1.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (0.7.4)\n",
      "Requirement already satisfied: setuptools in /root/venv/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (57.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (3.10.0.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (0.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (2.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (2.4.1)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (0.3.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (2.0.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (8.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from spacy<4->fastai==2.5.2) (3.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.4->spacy<4->fastai==2.5.2) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging->fastai==2.5.2) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<4->fastai==2.5.2) (5.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests->fastai==2.5.2) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->fastai==2.5.2) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->fastai==2.5.2) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->fastai==2.5.2) (2021.5.30)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from typer<0.4.0,>=0.3.0->spacy<4->fastai==2.5.2) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jinja2->spacy<4->fastai==2.5.2) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from matplotlib->fastai==2.5.2) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib->fastai==2.5.2) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib->fastai==2.5.2) (1.3.1)\n",
      "Requirement already satisfied: six in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->fastai==2.5.2) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pandas->fastai==2.5.2) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn->fastai==2.5.2) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn->fastai==2.5.2) (2.2.0)\n",
      "Installing collected packages: fastprogress, fastcore, fastdownload, fastai\n",
      "Successfully installed fastai-2.5.2 fastcore-1.3.26 fastdownload-0.0.5 fastprogress-1.0.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai==2.5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-9e6a2bc6-d8b7-4c99-b5a9-c3ae85de34e3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "##  Looking at the Data [Pandas]\n",
    "For this notebook, we'll be looking at the Amazon Reviews Polarity dataset! The task is to predict whether a review is of positive or negative sentiment. The original Amazon Reviews dataset contains review scores ranging from 1-5. This polarity dataset combines review scores 1-2 into the negative class, 4-5 into the positive class, and ignores/drops review scores of 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-ed76a823-8827-4469-854a-c8d9db36ee45",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12,
    "execution_start": 1630312659658,
    "source_hash": "b263a8a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from fastai.text.all import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00001-d6490b41-b70f-4c1a-936c-63ac3db853b1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 47282,
    "execution_start": 1630222851227,
    "source_hash": "240cc76a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('f:/Notebooks/.fastai/data/amazon_review_polarity_csv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.AMAZON_REVIEWS_POLARITY)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-a0e670c8-6fbe-44a1-bbb6-43315a6f3c4f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Let's go ahead and take a look at our two df's: train_df and valid_df\n",
    "We’re going to use 40k instead of 3.6m samples for training, and 2k instead of 400k samples for validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-f2c72e2a-771b-435e-8c25-9f25241f55ae",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 207,
    "execution_start": 1630223589402,
    "source_hash": "99b75223"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer</td>\n",
       "      <td>This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!</td>\n",
       "      <td>This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you've played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time's Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer's work (I haven't heard the Xenogears s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Uns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After Hearing it</td>\n",
       "      <td>If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                   title  \\\n",
       "0      2                          Stuning even for the non-gamer   \n",
       "1      2                   The best soundtrack ever to anything.   \n",
       "2      2                                                Amazing!   \n",
       "3      2                                    Excellent Soundtrack   \n",
       "4      2  Remember, Pull Your Jaw Off The Floor After Hearing it   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "0                                                                                                                                                                                                               This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^  \n",
       "1                                                                                                                                   I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.  \n",
       "2  This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you've played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time's Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer's work (I haven't heard the Xenogears s...  \n",
       "3  I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Uns...  \n",
       "4                                                                                                                                                                                If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(path/'train.csv', names=['label', 'title', 'text'], nrows=40000)\n",
    "valid_df = pd.read_csv(path/'test.csv', names=['label', 'title', 'text'], nrows=2000)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00003-704cbebc-5030-4e88-9675-43c57d160440",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 80,
    "execution_start": 1630226615565,
    "source_hash": "14d99d56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = train_df['text'][0]\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-02b151b0-da74-47c4-b425-71303373883c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### We need to Install torchtext for next Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00005-524ec171-1b32-4a9b-b6ca-20ec7d809020",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3522,
    "execution_start": 1630226648064,
    "source_hash": "60f55b34",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.10.0\n",
      "  Using cached torchtext-0.10.0-cp36-cp36m-win_amd64.whl (1.3 MB)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext==0.10.0) (2.24.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext==0.10.0) (1.19.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext==0.10.0) (4.50.2)\n",
      "Requirement already satisfied: torch==1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext==0.10.0) (1.9.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext==0.10.0) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext==0.10.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext==0.10.0) (2021.5.30)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.9.0->torchtext==0.10.0) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.9.0->torchtext==0.10.0) (0.8)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-4efafcef-9675-4d48-8aa8-da23b8e07b11",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "##  Tokenization and Numericalization [PyTorch]\n",
    "We now want to first tokenize our inputs, then numericalize them using a vocab. Quick recap of these terms:\n",
    "\n",
    "Tokenization = The process of converting an input string into \"pieces\"\n",
    "These pieces can be whole words, sub words, or even characters\n",
    "Numericalization = The process of converting a token into a numeric representation\n",
    "(e.g. token -> number)\n",
    "This is done through the use (and creation of) a vocab\n",
    "There are many fancy tokenizers out there, but since we're first doing things from scratch we'll go ahead and use a simple basic_english tokenizer from torchtext and split on spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00005-a26d6b34-8adc-4dab-8222-984799febadb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1630226659951,
    "source_hash": "40971f50",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-ce251596-c226-49c3-8d54-bba6d2cc4ade",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "##### Fastai’s L is basically list from Python, but has some convienent properties such as displaying the number of elements, and additionally doesn’t spam your screen with output if the list is too long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00007-572d7657-4c04-4835-96e9-818223bd50bb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1630226681142,
    "source_hash": "72f05792",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#81) ['this','sound','track','was','beautiful','!','it','paints','the','senery'...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = L(tokenizer(sample_text))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-76b6c11b-90c5-47fc-b9c6-cb56a6777549",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "##### Next we'll need to check how many tokens there are in our dataset, and keep the frequent ones as part of our vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00008-c07c9ada-c661-4dad-8cec-be1afe7a8cc6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2189,
    "execution_start": 1630226707791,
    "source_hash": "dca0265",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 213962),\n",
       " ('the', 158787),\n",
       " (',', 116525),\n",
       " ('i', 91270),\n",
       " ('and', 86059),\n",
       " ('a', 77977),\n",
       " ('to', 74984),\n",
       " ('it', 69999),\n",
       " ('of', 65144),\n",
       " (\"'\", 60523),\n",
       " ('this', 59382),\n",
       " ('is', 56445),\n",
       " ('in', 37890),\n",
       " ('that', 33891),\n",
       " ('for', 30532),\n",
       " ('was', 29163),\n",
       " ('you', 26740),\n",
       " ('!', 25238),\n",
       " ('book', 24698),\n",
       " ('s', 23897),\n",
       " ('but', 22602),\n",
       " ('with', 21998),\n",
       " ('not', 21988),\n",
       " ('on', 20759),\n",
       " ('t', 20097)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "token_counter = Counter()\n",
    "\n",
    "for sample_text in train_df['text']:\n",
    "    tokens = tokenizer(sample_text)\n",
    "    token_counter.update(tokens)\n",
    "\n",
    "token_counter.most_common(n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00009-fed9e59d-859a-46af-9663-83513e158562",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1630226771647,
    "source_hash": "4279bfa9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75889"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-65f35930-e7c7-4ea1-9593-a1854f44ffb3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Now that we have our token frequency counter, we can go ahead and make our vocab!\n",
    "\n",
    "##### Important: We’ll be using <unk> as our default token for tokens that are out of our vocab!\n",
    " Important: Notice how we passed in a min_freq argument. This ensures that the vocab only includes high frequency tokens. We wouldn’t want to include tokens that only occur once/rarely. This brought our vocab count down from 75,889 to 7,591! A ~90% reduction!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "00010-97b99962-0843-4d73-8695-9c380fd49098",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 17,
    "execution_start": 1630226791817,
    "source_hash": "81da7b60",
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext.vocab' has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-31d29dd199b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create vocab containing tokens with a minimum frequency of 20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmy_vocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_counter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Add the unknown token, and use this by default for unknown words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchtext.vocab' has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "sorted_counter = dict(token_counter.most_common())\n",
    "\n",
    "# Create vocab containing tokens with a minimum frequency of 20\n",
    "my_vocab = torchtext.vocab.vocab(sorted_counter, min_freq=20)\n",
    "\n",
    "# Add the unknown token, and use this by default for unknown words\n",
    "unk_token = '<unk>'\n",
    "my_vocab.insert_token(unk_token, 0)\n",
    "my_vocab.set_default_index(0)\n",
    "\n",
    "# Add the pad token\n",
    "pad_token = '<pad>'\n",
    "my_vocab.insert_token(pad_token, 1)\n",
    "\n",
    "# Show vocab size, and examples of tokens\n",
    "len(my_vocab.get_itos()), my_vocab.get_itos()[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-0a9eadf3-b537-489f-a69c-e12a090d09bf",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Rather than starting from scratch, we can preload GloVe embeddings into our vocabulary!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00011-b4c1eee3-f3a5-4abf-81d4-8a756d00e22a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 215600,
    "execution_start": 1630226855779,
    "source_hash": "7a5a875e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.6B.zip: 862MB [29:27, 488kB/s]                                                                     \n",
      "100%|██████████████████████████████████████████████████████████████████████▉| 399999/400000 [00:33<00:00, 11839.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([400000, 100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = torchtext.vocab.GloVe(name = '6B', dim = 100)\n",
    "glove.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-8b938670-ecc6-4359-828c-786db3d73825",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Since we're using GloVe vectors for transfer learning (by preloading our embedding), let's take a look at how many tokens can be successfully transferred from GloVe into our own vocab. Each token will have an embedding (vector) of size 100. This results in an embedding of size 7591x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-fec28f5f-0e16-4333-9d0b-1699240beb54",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1630227110386,
    "source_hash": "b5badf14",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7591, 100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vocab.vectors = glove.get_vecs_by_tokens(my_vocab.get_itos())\n",
    "my_vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-6e8d5472-afa1-4498-affd-d5b7af760fec",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "##### By default, tokens that aren't able to transfer from GloVe into our own dataset get initialized with a vector of 0's. We can use this to count how many tokens were successfully preloaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-7a29a0e4-f00e-4a04-9619-681948153c4c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 332,
    "execution_start": 1630312638651,
    "source_hash": "1f8fc463",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73/193076880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtot_transferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtot_transferred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_vocab' is not defined"
     ]
    }
   ],
   "source": [
    "tot_transferred = 0\n",
    "for v in my_vocab.vectors:\n",
    "    if not v.equal(torch.zeros(100)):\n",
    "        tot_transferred += 1\n",
    "        \n",
    "tot_transferred, len(my_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=49aec45e-6e0f-4e9f-a765-361581a0655a' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "eb5af2e5-5a53-4de0-b34f-4247625520b7",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
